{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import os.path\n",
    "import argparse\n",
    "\n",
    "import gym\n",
    "gym.logger.set_level(40) # remove gym warning about float32 bound box precision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import common.env_lib\n",
    "from common.env_utils import sorl_plot\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--env\", default=\"csense\", type=str, help=\"Environment. Specified in ./common/env_lib.py\")\n",
    "# parser.add_argument(\"--seed\", default=238, type=int, help=\"Set seed [default: 238]\")\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "# arguments\n",
    "seed      = 123#args.seed\n",
    "env_name  = \"csense\"#args.env\n",
    "\n",
    "\n",
    "# set seed\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "timeslots_per_day = 24\n",
    "env = eval(\"common.env_lib.\"+env_name+\"()\")\n",
    "\n",
    "naive_heuristics={'c00':0.0, # minimum sense_dc\n",
    "                  'c01':0.1, # 10% conformity\n",
    "                  'c02':0.2, # 20% conformity\n",
    "                  'c03':0.3, # 30% conformity\n",
    "                  'c04':0.4, # 40% conformity\n",
    "                  'c05':0.5, # 50% conformity\n",
    "                  'c06':0.6, # 60% conformity\n",
    "                  'c07':0.7, # 70% conformity\n",
    "                  'c08':0.8, # 80% conformity\n",
    "                  'c09':0.9, # 90% conformity\n",
    "                  'c10':1.0} # maximum conformity\n",
    "                  \n",
    "\n",
    "cur_folder = os.getcwd()\n",
    "for experiment in list(naive_heuristics.keys()):\n",
    "    env_location_list = ['tokyo']#,'wakkanai','minamidaito']\n",
    "    START_YEAR = 1995\n",
    "    NO_OF_YEARS = 24\n",
    "    timeslots_per_day = 24\n",
    "    REQ_TYPE = \"random\"\n",
    "    prediction_horizon = 10*timeslots_per_day\n",
    "    henergy_mean= 0.13904705134356052 # 10yr hmean for tokyo\n",
    "    DEFAULT_ACTION = naive_heuristics[experiment]\n",
    "    \n",
    "    # Tags\n",
    "    env_tag = env_name + '_t' + str(timeslots_per_day) + '_' + REQ_TYPE\n",
    "    model_tag = experiment +'-'+str(seed)\n",
    "\n",
    "    # experiment tag\n",
    "    # name of folder to save models and results\n",
    "    exp_tag = env_tag  + \"-\" + experiment \n",
    "\n",
    "    # experiment+seed tag\n",
    "    # tensorboard tag / model filename\n",
    "    tag     = exp_tag +'-' + str(seed) \n",
    "#     print(\"Experiment tag: \",tag)\n",
    "    \n",
    "    # Folder/file to save test results\n",
    "    test_results_folder = os.path.join(cur_folder,\"results\", exp_tag, \"test\")\n",
    "    if not os.path.exists(test_results_folder): \n",
    "            os.makedirs(test_results_folder) \n",
    "    test_log_file = os.path.join(test_results_folder, tag + '-test.npy')    \n",
    " \n",
    "    \n",
    "    exp_result = {}\n",
    "    for env_location in env_location_list:\n",
    "#         print(env_location, end='\\t')\n",
    "        exp_result[env_location] = {}\n",
    "        for year in range(START_YEAR, START_YEAR+NO_OF_YEARS):\n",
    "            env.set_env(env_location, year , timeslots_per_day, \n",
    "                        REQ_TYPE, offset=timeslots_per_day/2,\n",
    "                        p_horizon=prediction_horizon,\n",
    "                        hmean=henergy_mean)    \n",
    "            state = env.reset()\n",
    "            reward_rec = []\n",
    "            ep_done_rec = []\n",
    "            done = False\n",
    "            while not done:\n",
    "                if env.RECOVERY_MODE:\n",
    "                    no_action = 0            \n",
    "                    next_state, reward, done, _ = env.step(no_action)       \n",
    "                else:\n",
    "                    next_state, reward, done, _ = env.step(DEFAULT_ACTION)         \n",
    "                reward_rec.append(reward)\n",
    "                ep_done = done or env.RECOVERY_MODE\n",
    "                ep_done_rec.append(ep_done)\n",
    "                state = next_state\n",
    "\n",
    "            # Log the traces and summarize results\n",
    "            iteration_result={}\n",
    "            \n",
    "            # Saving traces\n",
    "            iteration_result['reward_rec'] = np.array(reward_rec)\n",
    "            iteration_result['ep_done_rec'] = np.array(ep_done_rec)\n",
    "            iteration_result['action_log'] = np.array(env.action_log)\n",
    "            iteration_result['sense_dc_log'] = np.array(env.sense_dc_log)\n",
    "            iteration_result['env_log'] = np.array(env.env_log)\n",
    "            iteration_result['eno_log'] = np.array(env.eno_log)\n",
    "            iteration_result['sense_reward_log'] = np.array(env.sense_reward_log)\n",
    "            iteration_result['enp_reward_log'] = np.array(env.enp_reward_log)\n",
    "            \n",
    "            # Summarizing results\n",
    "            env_log = iteration_result['env_log']\n",
    "\n",
    "            # Get henergy metrics\n",
    "            henergy_rec = env_log[:,1]\n",
    "            avg_henergy = henergy_rec.mean()\n",
    "            iteration_result['avg_henergy'] = avg_henergy\n",
    "\n",
    "            # Get req metrics\n",
    "            req_rec = env_log[:,5]\n",
    "            avg_req = req_rec.mean()            \n",
    "            iteration_result['avg_req'] = avg_req\n",
    "\n",
    "            # Get reward metrics\n",
    "            # In this case, the reward metrics directly reflect the conformity\n",
    "            reward_rec = iteration_result['reward_rec']\n",
    "            # negative rewards = -1000 correspond to downtimes\n",
    "            # To find average reward, remove negative values\n",
    "            index = np.argwhere(reward_rec<0)\n",
    "            rwd_rec = np.delete(reward_rec, index)\n",
    "            avg_rwd = rwd_rec.mean()\n",
    "            iteration_result['avg_rwd'] = avg_rwd\n",
    "\n",
    "            # Get downtime metrics\n",
    "            batt_rec = env_log[:,3]\n",
    "            batt_rec[batt_rec>0.1]=0\n",
    "            batt_rec[batt_rec!=0]=1\n",
    "            downtimes = np.count_nonzero(batt_rec[:-1] < batt_rec[1:])\n",
    "            iteration_result['downtimes'] = downtimes\n",
    "\n",
    "            # Get ENP metrics\n",
    "            eno_log = iteration_result['eno_log']\n",
    "            enp_log = []\n",
    "            enp_log.append(eno_log[0])\n",
    "            for t in range(1,len(eno_log)):\n",
    "                enp = enp_log[-1] + eno_log[t]\n",
    "                enp = np.clip(enp,0,1)\n",
    "                enp_log.append(enp)\n",
    "            iteration_result['enp_log'] = np.array(enp_log)\n",
    "#             print(year,end=\", \")            \n",
    "            exp_result[env_location][year] = iteration_result\n",
    "#     print('')\n",
    "    np.save(test_log_file, exp_result)\n",
    "\n",
    "# summarize metrics and display\n",
    "\n",
    "for experiment in list(naive_heuristics.keys()):\n",
    "    \n",
    "    # Tags\n",
    "    env_tag = env_name + '_t' + str(timeslots_per_day) + '_' + REQ_TYPE\n",
    "    model_tag = experiment +'-'+str(seed)\n",
    "\n",
    "    # experiment tag\n",
    "    # name of folder to save models and results\n",
    "    exp_tag = env_tag  + \"-\" + experiment \n",
    "\n",
    "    # experiment+seed tag\n",
    "    tag     = exp_tag +'-'+str(seed)     \n",
    "    \n",
    "    # Folder/file to load test results\n",
    "    test_results_folder = os.path.join(cur_folder,\"results\", exp_tag, \"test\")\n",
    "    if not os.path.exists(test_results_folder): \n",
    "        print(\"Experiment has not been run\")\n",
    "    test_log_file = os.path.join(test_results_folder, tag + '-test.npy')    \n",
    " \n",
    "    # Load data\n",
    "    exp_result = np.load(test_log_file,allow_pickle='TRUE').item()    \n",
    "    \n",
    "    print(\"Experiment:\", tag)\n",
    "    print(\"LOCATION\".ljust(12), \"YEAR\".ljust(6), \"HMEAN\".ljust(8), \"REQ_MEAN\".ljust(8), \"AVG_DC\".ljust(8), \n",
    "      \"SNS_RWD\".ljust(8), \"ENP_RWD\".ljust(8), \"AVG_RWD\".ljust(8), \"DOWNTIMES\".ljust(9))\n",
    "\n",
    "    location_list = list(exp_result.keys())\n",
    "    for location in location_list:\n",
    "        yr_list = list(exp_result[location].keys())\n",
    "        for year in yr_list:\n",
    "            run_log = exp_result[location][year]\n",
    "            # Print summarized metrics\n",
    "            print(location.ljust(12), year, end=' ')\n",
    "            sense_avg_rwd = run_log['sense_reward_log'].mean()\n",
    "            enp_avg_rwd = run_log['enp_reward_log'].mean()\n",
    "\n",
    "            average_rwd = run_log['avg_rwd']\n",
    "            total_downtimes = run_log['downtimes']\n",
    "            hmean = run_log['avg_henergy']\n",
    "            reqmean = run_log['avg_req']\n",
    "            sense_dc_mean = run_log['sense_dc_log'].mean()\n",
    "\n",
    "            print(f'{hmean:7.3f}',end='  ')\n",
    "            print(f'{reqmean:7.3f}',end='  ')\n",
    "            print(f'{sense_dc_mean:7.3f}',end='  ')\n",
    "            print(f'{sense_avg_rwd:7.3f}',end='  ')\n",
    "            print(f'{enp_avg_rwd:7.3f}',end='  ')\n",
    "            print(f'{average_rwd:7.3f}',end='  ')\n",
    "            print(f'{total_downtimes:5d}',end='  ')\n",
    "            print(\"\")\n",
    "    print('*'*90)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
