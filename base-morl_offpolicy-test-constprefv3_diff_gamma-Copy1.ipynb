{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rc('font', family='serif', serif='Times')\n",
    "# plt.rc('text', usetex=True)\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=8)\n",
    "matplotlib.rcParams['lines.linewidth'] = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[382084, 959804, 880775, 707317, 638913, 160861, 468738, 814726, 792012, 752389]\n"
     ]
    }
   ],
   "source": [
    "# Get seedlist\n",
    "file = 'seedlist.dat'\n",
    "with open(file) as f:\n",
    "    seed_list = []\n",
    "    for line in f: # read rest of lines\n",
    "        seed_list.append([int(x) for x in line.split()][0])\n",
    "print(seed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    }
   ],
   "source": [
    "# Set mode to train or test\n",
    "mode = \"train\"\n",
    "print(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each preference as a different experiment in results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6e4774782e2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0mdummy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallpref_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpref\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'downtimes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0mallpref_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"minimum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpref\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'downtimes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mallpref_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"first_q\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpref\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'downtimes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# Define list of experiments to analyze for given seed\n",
    "allpref_experiment_list=['cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.2-intrp4']\n",
    "allpref_results = {} # dictionary to hold experimental data\n",
    "\n",
    "for experiment in allpref_experiment_list:\n",
    "    allpref_results[experiment]={}        \n",
    "    for seed_no in seed_list:\n",
    "        # Load data of experiment and store in a dictionary\n",
    "        tag = experiment + '-' + str(seed_no)\n",
    "        cur_folder = os.getcwd()\n",
    "        exp_results_folder = os.path.join(cur_folder,\"results\", experiment, mode) # experiment folder\n",
    "        exp_results_file = os.path.join(exp_results_folder, tag + '-'+ mode + '.npy') # experiment data file\n",
    "        exp_result = np.load(exp_results_file,allow_pickle='TRUE').item()\n",
    "        allpref_results[experiment][seed_no] = exp_result # load to dictionary\n",
    "\n",
    "# Get list of locations and years in the experimental data\n",
    "location_list   = list(allpref_results[allpref_experiment_list[0]][seed_list[0]].keys())\n",
    "year_list       = list(allpref_results[allpref_experiment_list[0]][seed_list[0]][location_list[0]].keys())\n",
    "pref_list       = list(allpref_results[allpref_experiment_list[0]][seed_list[0]][location_list[0]][year_list[0]].keys())\n",
    "\n",
    "# Add keys to dictionaries\n",
    "for experiment in allpref_experiment_list:\n",
    "    allpref_results[experiment][\"minimum\"] = {}\n",
    "    allpref_results[experiment][\"first_q\"] = {}\n",
    "    allpref_results[experiment][\"average\"] = {}\n",
    "    allpref_results[experiment][\"third_q\"] = {}\n",
    "    allpref_results[experiment][\"maximum\"] = {}\n",
    "    for location in location_list:\n",
    "        allpref_results[experiment][\"minimum\"][location] = {}\n",
    "        allpref_results[experiment][\"first_q\"][location] = {}\n",
    "        allpref_results[experiment][\"average\"][location] = {}\n",
    "        allpref_results[experiment][\"third_q\"][location] = {}\n",
    "        allpref_results[experiment][\"maximum\"][location] = {}\n",
    "        for year in year_list:\n",
    "            allpref_results[experiment][\"minimum\"][location][year] = {}\n",
    "            allpref_results[experiment][\"first_q\"][location][year] = {}\n",
    "            allpref_results[experiment][\"average\"][location][year] = {}\n",
    "            allpref_results[experiment][\"third_q\"][location][year] = {}\n",
    "            allpref_results[experiment][\"maximum\"][location][year] = {}\n",
    "            for pref in pref_list:\n",
    "                allpref_results[experiment][\"minimum\"][location][year][pref] = {}\n",
    "                allpref_results[experiment][\"first_q\"][location][year][pref] = {}\n",
    "                allpref_results[experiment][\"average\"][location][year][pref] = {}\n",
    "                allpref_results[experiment][\"third_q\"][location][year][pref] = {}\n",
    "                allpref_results[experiment][\"maximum\"][location][year][pref] = {}\n",
    "\n",
    "# get min, avg and max downtimes\n",
    "for experiment in allpref_experiment_list:\n",
    "    for location in location_list:\n",
    "        for year in year_list:\n",
    "            for pref in pref_list:\n",
    "                dummy = []\n",
    "                for seed in seed_list:\n",
    "                    dummy.append(allpref_results[experiment][seed][location][year][pref]['downtimes'])\n",
    "                allpref_results[experiment][\"minimum\"][location][year][pref]['downtimes'] = np.min(dummy)\n",
    "                allpref_results[experiment][\"first_q\"][location][year][pref]['downtimes'] = np.percentile(dummy, 25)\n",
    "                allpref_results[experiment][\"average\"][location][year][pref]['downtimes'] = np.mean(dummy)\n",
    "                allpref_results[experiment][\"third_q\"][location][year][pref]['downtimes'] = np.percentile(dummy, 75)\n",
    "                allpref_results[experiment][\"maximum\"][location][year][pref]['downtimes'] = np.max(dummy)\n",
    "\n",
    "# get min, avg and max avg_sense_reward\n",
    "for experiment in allpref_experiment_list:\n",
    "    for location in location_list:\n",
    "        for year in year_list:\n",
    "            for pref in pref_list:\n",
    "                dummy = []\n",
    "                for seed in seed_list:\n",
    "                    avgsnsrwd = allpref_results[experiment][seed][location][year][pref]['sense_reward_log'].mean()\n",
    "                    allpref_results[experiment][seed][location][year][pref]['avg_sense_reward'] = avgsnsrwd # add new entry\n",
    "                    dummy.append(avgsnsrwd)\n",
    "                allpref_results[experiment][\"minimum\"][location][year][pref]['avg_sense_reward'] = np.min(dummy)\n",
    "                allpref_results[experiment][\"first_q\"][location][year][pref]['avg_sense_reward'] = np.percentile(dummy, 25)\n",
    "                allpref_results[experiment][\"average\"][location][year][pref]['avg_sense_reward'] = np.mean(dummy)\n",
    "                allpref_results[experiment][\"third_q\"][location][year][pref]['avg_sense_reward'] = np.percentile(dummy, 75)\n",
    "                allpref_results[experiment][\"maximum\"][location][year][pref]['avg_sense_reward'] = np.max(dummy)\n",
    "            \n",
    "# get min, avg and max avg_enp_reward\n",
    "for experiment in allpref_experiment_list:\n",
    "    for location in location_list:\n",
    "        for year in year_list:\n",
    "            dummy = []\n",
    "            for seed in seed_list:\n",
    "                avgenprwd = allpref_results[experiment][seed][location][year][pref]['enp_reward_log'].mean()\n",
    "                allpref_results[experiment][seed][location][year][pref]['avg_enp_reward'] = avgenprwd # add new entry\n",
    "                dummy.append(avgenprwd)\n",
    "            allpref_results[experiment][\"minimum\"][location][year][pref]['avg_enp_reward'] = np.min(dummy)\n",
    "            allpref_results[experiment][\"first_q\"][location][year][pref]['avg_enp_reward'] = np.percentile(dummy, 25)\n",
    "            allpref_results[experiment][\"average\"][location][year][pref]['avg_enp_reward'] = np.mean(dummy)\n",
    "            allpref_results[experiment][\"third_q\"][location][year][pref]['avg_enp_reward'] = np.percentile(dummy, 75)\n",
    "            allpref_results[experiment][\"maximum\"][location][year][pref]['avg_enp_reward'] = np.max(dummy)\n",
    "\n",
    "\n",
    "\n",
    "location = 'tokyo'\n",
    "for pref in pref_list:\n",
    "    for experiment in allpref_experiment_list:\n",
    "        exp_tag = experiment+'-p'+str(pref)\n",
    "        results[exp_tag] = {}\n",
    "        for seed in seed_list:\n",
    "            results[exp_tag][seed] = {}\n",
    "            for location in location_list:\n",
    "                results[exp_tag][seed][location] = {}\n",
    "                for year in year_list:\n",
    "                    results[exp_tag][seed][location][year] =  allpref_results[experiment][seed][location][year][pref]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of experiments to analyze for given seed\n",
    "allpref_experiment_list=['cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.8-intrp4',\n",
    "                        ]\n",
    "allpref_results = {} # dictionary to hold experimental data\n",
    "\n",
    "for experiment in allpref_experiment_list:\n",
    "    allpref_results[experiment]={}        \n",
    "    for seed_no in seed_list:\n",
    "        # Load data of experiment and store in a dictionary\n",
    "        tag = experiment + '-' + str(seed_no)\n",
    "        cur_folder = os.getcwd()\n",
    "        exp_results_folder = os.path.join(cur_folder,\"results\", experiment, mode) # experiment folder\n",
    "        exp_results_file = os.path.join(exp_results_folder, tag + '-'+ mode + '.npy') # experiment data file\n",
    "        exp_result = np.load(exp_results_file,allow_pickle='TRUE').item()\n",
    "        allpref_results[experiment][seed_no] = exp_result # load to dictionary\n",
    "\n",
    "# Get list of locations and years in the experimental data\n",
    "location_list   = list(allpref_results[allpref_experiment_list[0]][seed_list[0]].keys())\n",
    "year_list       = list(allpref_results[allpref_experiment_list[0]][seed_list[0]][location_list[0]].keys())\n",
    "pref_list       = list(allpref_results[allpref_experiment_list[0]][seed_list[0]][location_list[0]][year_list[0]].keys())\n",
    "\n",
    "# Add keys to dictionaries\n",
    "for experiment in allpref_experiment_list:\n",
    "    allpref_results[experiment][\"minimum\"] = {}\n",
    "    allpref_results[experiment][\"first_q\"] = {}\n",
    "    allpref_results[experiment][\"average\"] = {}\n",
    "    allpref_results[experiment][\"third_q\"] = {}\n",
    "    allpref_results[experiment][\"maximum\"] = {}\n",
    "    for location in location_list:\n",
    "        allpref_results[experiment][\"minimum\"][location] = {}\n",
    "        allpref_results[experiment][\"first_q\"][location] = {}\n",
    "        allpref_results[experiment][\"average\"][location] = {}\n",
    "        allpref_results[experiment][\"third_q\"][location] = {}\n",
    "        allpref_results[experiment][\"maximum\"][location] = {}\n",
    "        for year in year_list:\n",
    "            allpref_results[experiment][\"minimum\"][location][year] = {}\n",
    "            allpref_results[experiment][\"first_q\"][location][year] = {}\n",
    "            allpref_results[experiment][\"average\"][location][year] = {}\n",
    "            allpref_results[experiment][\"third_q\"][location][year] = {}\n",
    "            allpref_results[experiment][\"maximum\"][location][year] = {}\n",
    "            for pref in pref_list:\n",
    "                allpref_results[experiment][\"minimum\"][location][year][pref] = {}\n",
    "                allpref_results[experiment][\"first_q\"][location][year][pref] = {}\n",
    "                allpref_results[experiment][\"average\"][location][year][pref] = {}\n",
    "                allpref_results[experiment][\"third_q\"][location][year][pref] = {}\n",
    "                allpref_results[experiment][\"maximum\"][location][year][pref] = {}\n",
    "\n",
    "# get min, avg and max downtimes\n",
    "for experiment in allpref_experiment_list:\n",
    "    for location in location_list:\n",
    "        for year in year_list:\n",
    "            for pref in pref_list:\n",
    "                dummy = []\n",
    "                for seed in seed_list:\n",
    "                    dummy.append(allpref_results[experiment][seed][location][year][pref]['downtimes'])\n",
    "                allpref_results[experiment][\"minimum\"][location][year][pref]['downtimes'] = np.min(dummy)\n",
    "                allpref_results[experiment][\"first_q\"][location][year][pref]['downtimes'] = np.percentile(dummy, 25)\n",
    "                allpref_results[experiment][\"average\"][location][year][pref]['downtimes'] = np.mean(dummy)\n",
    "                allpref_results[experiment][\"third_q\"][location][year][pref]['downtimes'] = np.percentile(dummy, 75)\n",
    "                allpref_results[experiment][\"maximum\"][location][year][pref]['downtimes'] = np.max(dummy)\n",
    "\n",
    "# get min, avg and max avg_sense_reward\n",
    "for experiment in allpref_experiment_list:\n",
    "    for location in location_list:\n",
    "        for year in year_list:\n",
    "            for pref in pref_list:\n",
    "                dummy = []\n",
    "                for seed in seed_list:\n",
    "                    avgsnsrwd = allpref_results[experiment][seed][location][year][pref]['sense_reward_log'].mean()\n",
    "                    allpref_results[experiment][seed][location][year][pref]['avg_sense_reward'] = avgsnsrwd # add new entry\n",
    "                    dummy.append(avgsnsrwd)\n",
    "                allpref_results[experiment][\"minimum\"][location][year][pref]['avg_sense_reward'] = np.min(dummy)\n",
    "                allpref_results[experiment][\"first_q\"][location][year][pref]['avg_sense_reward'] = np.percentile(dummy, 25)\n",
    "                allpref_results[experiment][\"average\"][location][year][pref]['avg_sense_reward'] = np.mean(dummy)\n",
    "                allpref_results[experiment][\"third_q\"][location][year][pref]['avg_sense_reward'] = np.percentile(dummy, 75)\n",
    "                allpref_results[experiment][\"maximum\"][location][year][pref]['avg_sense_reward'] = np.max(dummy)\n",
    "            \n",
    "# get min, avg and max avg_enp_reward\n",
    "for experiment in allpref_experiment_list:\n",
    "    for location in location_list:\n",
    "        for year in year_list:\n",
    "            dummy = []\n",
    "            for seed in seed_list:\n",
    "                avgenprwd = allpref_results[experiment][seed][location][year][pref]['enp_reward_log'].mean()\n",
    "                allpref_results[experiment][seed][location][year][pref]['avg_enp_reward'] = avgenprwd # add new entry\n",
    "                dummy.append(avgenprwd)\n",
    "            allpref_results[experiment][\"minimum\"][location][year][pref]['avg_enp_reward'] = np.min(dummy)\n",
    "            allpref_results[experiment][\"first_q\"][location][year][pref]['avg_enp_reward'] = np.percentile(dummy, 25)\n",
    "            allpref_results[experiment][\"average\"][location][year][pref]['avg_enp_reward'] = np.mean(dummy)\n",
    "            allpref_results[experiment][\"third_q\"][location][year][pref]['avg_enp_reward'] = np.percentile(dummy, 75)\n",
    "            allpref_results[experiment][\"maximum\"][location][year][pref]['avg_enp_reward'] = np.max(dummy)\n",
    "\n",
    "\n",
    "\n",
    "location = 'tokyo'\n",
    "for pref in pref_list:\n",
    "    for experiment in allpref_experiment_list:\n",
    "        exp_tag = experiment+'-p'+str(pref)\n",
    "        results[exp_tag] = {}\n",
    "        for seed in seed_list:\n",
    "            results[exp_tag][seed] = {}\n",
    "            for location in location_list:\n",
    "                results[exp_tag][seed][location] = {}\n",
    "                for year in year_list:\n",
    "                    results[exp_tag][seed][location][year] =  allpref_results[experiment][seed][location][year][pref]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load other additional experiments\n",
    "other_experiment_list=[\n",
    "    'csense_t24_random-base_g0.997-n0.7',\n",
    "#     'cenp_t24_random-base_g0.997-n0.7',\n",
    "    'cenp_t24_random-morl_runtimev2_g0.997-n0.7-p0.2',\n",
    "    'cenp_t24_random-morl_runtimev2_g0.997-n0.7-p0.8',\n",
    "]\n",
    "\n",
    "for experiment in other_experiment_list:\n",
    "    results[experiment]={}        \n",
    "    for seed_no in seed_list:\n",
    "        # Load data of experiment and store in a dictionary\n",
    "        tag = experiment + '-' + str(seed_no)\n",
    "        cur_folder = os.getcwd()\n",
    "        exp_results_folder = os.path.join(cur_folder,\"results\", experiment, mode) # experiment folder\n",
    "        exp_results_file = os.path.join(exp_results_folder, tag + '-'+ mode + '.npy') # experiment data file\n",
    "        exp_result = np.load(exp_results_file,allow_pickle='TRUE').item()\n",
    "        results[experiment][seed_no] = exp_result # load to dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of experiments to analyze for given seed\n",
    "experiment_list=[\n",
    "    'csense_t24_random-base_g0.997-n0.7',\n",
    "#     'cenp_t24_random-base_g0.997-n0.7',\n",
    "\n",
    "#     'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.1-intrp4-p0.1',\n",
    "    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.2-intrp4-p0.2',\n",
    "    'cenp_t24_random-morl_runtimev2_g0.997-n0.7-p0.2',\n",
    "\n",
    "    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.8-intrp4-p0.8',\n",
    "    'cenp_t24_random-morl_runtimev2_g0.997-n0.7-p0.8',\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_label = {'csense_t24_random-base_g0.997-n0.7':'sense',\n",
    "                    'cenp_t24_random-base_g0.997-n0.7':'enp',\n",
    "                    \n",
    "                    'cenpxsense_t24_random-base_g0.997-n0.7':'mul_scalar',\n",
    "                    \n",
    "                    'cenpsense_t24_random-base_g0.997-n0.7-p0.2':'add_scalar,0.2',\n",
    "                    'cenpsense_t24_random-base_g0.997-n0.7-p0.5':'add_scalar,0.5',\n",
    "                    'cenpsense_t24_random-base_g0.997-n0.7-p0.8':'add_scalar,0.8',\n",
    "                    \n",
    "                    'cenp_t24_random-morl_runtime_g0.997-n0.7-p0.2':'morl_runtime(0.2)',\n",
    "                    'cenp_t24_random-morl_runtime_g0.997-n0.7-p0.5':'morl_runtime,0.5',\n",
    "                    'cenp_t24_random-morl_runtime_g0.997-n0.7-p0.8':'morl_runtime(0.8)',\n",
    "                    \n",
    "                    'cenp_t24_random-morl_runtimev2_g0.997-n0.7-p0.2':'morl_runtime(0.2)',\n",
    "                    'cenp_t24_random-morl_runtimev2_g0.997-n0.7-p0.5':'morl_runtime(0.5)',\n",
    "                    'cenp_t24_random-morl_runtimev2_g0.997-n0.7-p0.8':'morl_runtime(0.8)',\n",
    "                    \n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-random_pref-intrp4-p0.2':'morl,0.2',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-random_pref-intrp4-p0.5':'morl,0.5', \n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-random_pref-intrp4-p0.8':'morl,0.8',\n",
    "                    \n",
    "                    'cenp_t24_random-off_policy_diffg0.997-n0.7-random_pref-intrp4-p0.2':'morl_dg,0.2',\n",
    "                    'cenp_t24_random-off_policy_diffg0.997-n0.7-random_pref-intrp4-p0.5':'morl_dg,0.5', \n",
    "                    'cenp_t24_random-off_policy_diffg0.997-n0.7-random_pref-intrp4-p0.8':'morl_dg,0.8',\n",
    "                    \n",
    "                    'cenp_t24_random-off_policy_diff2g0.997-n0.7-random_pref-intrp4-p0.2':'morl_dg2,0.2',\n",
    "                    'cenp_t24_random-off_policy_diff2g0.997-n0.7-random_pref-intrp4-p0.5':'morl_dg2,0.5', \n",
    "                    'cenp_t24_random-off_policy_diff2g0.997-n0.7-random_pref-intrp4-p0.8':'morl_dg2,0.8',\n",
    "    \n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.1-intrp4-p0.1':'morl_learner(0.1)',\n",
    "\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.2-intrp4-p0.2':'morl_learner(0.2)',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.2-intrp4-p0.5':'morl_cpf2,0.5',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.2-intrp4-p0.8':'morl_cpf2,0.8',\n",
    "                    \n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.5-intrp4-p0.2':'morl_cpf5,0.2',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.5-intrp4-p0.5':'morl_cpf5,0.5',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.5-intrp4-p0.8':'morl_cpf5,0.8',\n",
    "\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.8-intrp4-p0.2':'morl_cpf8,0.2',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.8-intrp4-p0.5':'morl_cpf8,0.5',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.8-intrp4-p0.8':'morl_learner(0.8)',\n",
    "                   }\n",
    "\n",
    "experiment_color = {'csense_t24_random-base_g0.997-n0.7':'tab:red',\n",
    "                    'cenp_t24_random-base_g0.997-n0.7':'tab:green',\n",
    "                    \n",
    "                    'cenpxsense_t24_random-base_g0.997-n0.7':'tab:brown',\n",
    "                    \n",
    "                    'cenpsense_t24_random-base_g0.997-n0.7-p0.2':'tab:cyan',\n",
    "                    'cenpsense_t24_random-base_g0.997-n0.7-p0.5':'tab:purple',\n",
    "                    'cenpsense_t24_random-base_g0.997-n0.7-p0.8':'tab:pink',\n",
    "                    \n",
    "                    'cenp_t24_random-morl_runtime_g0.997-n0.7-p0.2':'tab:cyan',\n",
    "                    'cenp_t24_random-morl_runtime_g0.997-n0.7-p0.5':'tab:purple',\n",
    "                    'cenp_t24_random-morl_runtime_g0.997-n0.7-p0.8':'tab:pink',\n",
    "                    \n",
    "                    'cenp_t24_random-morl_runtimev2_g0.997-n0.7-p0.2':'tab:blue',\n",
    "                    'cenp_t24_random-morl_runtimev2_g0.997-n0.7-p0.5':'tab:purple',\n",
    "                    'cenp_t24_random-morl_runtimev2_g0.997-n0.7-p0.8':'tab:brown',\n",
    "                    \n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-random_pref-intrp4-p0.2':'tab:blue',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-random_pref-intrp4-p0.5':'tab:orange', \n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-random_pref-intrp4-p0.8':'tab:green',\n",
    "                    \n",
    "                    'cenp_t24_random-off_policy_diffg0.997-n0.7-random_pref-intrp4-p0.2':'tab:cyan',\n",
    "                    'cenp_t24_random-off_policy_diffg0.997-n0.7-random_pref-intrp4-p0.5':'tab:purple', \n",
    "                    'cenp_t24_random-off_policy_diffg0.997-n0.7-random_pref-intrp4-p0.8':'tab:pink', \n",
    "                    \n",
    "                    'cenp_t24_random-off_policy_diff2g0.997-n0.7-random_pref-intrp4-p0.2':'tab:cyan',\n",
    "                    'cenp_t24_random-off_policy_diff2g0.997-n0.7-random_pref-intrp4-p0.5':'tab:purple', \n",
    "                    'cenp_t24_random-off_policy_diff2g0.997-n0.7-random_pref-intrp4-p0.8':'tab:pink', \n",
    "                    \n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.1-intrp4-p0.1':'tab:blue',\n",
    "\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.2-intrp4-p0.2':'tab:pink',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.2-intrp4-p0.5':'tab:orange',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.2-intrp4-p0.8':'tab:green',\n",
    "                    \n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.5-intrp4-p0.2':'tab:cyan',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.5-intrp4-p0.5':'tab:purple',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.5-intrp4-p0.8':'tab:pink',\n",
    "                    \n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.8-intrp4-p0.2':'tab:olive',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.8-intrp4-p0.5':'tab:red',\n",
    "                    'cenp_t24_random-off_policy_g0.997-n0.7-const_pref0.8-intrp4-p0.8':'tab:olive',\n",
    "\n",
    "\n",
    "                   }\n",
    "\n",
    "# experiment_linestyle = {'csense_t24_random-base_g0.997-n0.7':'tab:red',\n",
    "#                         'cenp_t24_random-base_g0.997-n0.7':'tab:green',\n",
    "\n",
    "#                         'cenpxsense_t24_random-base_g0.997-n0.7':'tab:brown',\n",
    "\n",
    "#                         'cenpsense_t24_random-base_g0.997-n0.7-p0.2':'tab:cyan',\n",
    "#                         'cenpsense_t24_random-base_g0.997-n0.7-p0.5':'tab:purple',\n",
    "#                         'cenpsense_t24_random-base_g0.997-n0.7-p0.8':'tab:pink',\n",
    "\n",
    "#                         'cenp_t24_random-off_policy_g0.997-n0.7-random_pref-intrp4-p0.2',\n",
    "#                         'cenp_t24_random-off_policy_g0.997-n0.7-random_pref-intrp4-p0.5', \n",
    "#                         'cenp_t24_random-off_policy_g0.997-n0.7-random_pref-intrp4-p0.8', \n",
    "\n",
    "#                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year_list  = list(allpref_results[allpref_experiment_list[0]][seed_list[0]][location_list[0]].keys())\n",
    "year_list  = list(np.arange(2005,2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of locations and years in the experimental data\n",
    "\n",
    "# Add keys to dictionaries\n",
    "for experiment in experiment_list:\n",
    "    results[experiment][\"minimum\"] = {}\n",
    "    results[experiment][\"first_q\"] = {}\n",
    "    results[experiment][\"average\"] = {}\n",
    "    results[experiment][\"third_q\"] = {}\n",
    "    results[experiment][\"maximum\"] = {}\n",
    "    for location in location_list:\n",
    "        results[experiment][\"minimum\"][location] = {}\n",
    "        results[experiment][\"first_q\"][location] = {}\n",
    "        results[experiment][\"average\"][location] = {}\n",
    "        results[experiment][\"third_q\"][location] = {}\n",
    "        results[experiment][\"maximum\"][location] = {}\n",
    "        for year in year_list:\n",
    "            results[experiment][\"minimum\"][location][year] = {}\n",
    "            results[experiment][\"first_q\"][location][year] = {}\n",
    "            results[experiment][\"average\"][location][year] = {}\n",
    "            results[experiment][\"third_q\"][location][year] = {}\n",
    "            results[experiment][\"maximum\"][location][year] = {}\n",
    "            \n",
    "\n",
    "\n",
    "# get min, avg and max downtimes\n",
    "for experiment in experiment_list:\n",
    "    for location in location_list:\n",
    "        for year in year_list:\n",
    "            dummy = []\n",
    "            for seed in seed_list:\n",
    "                dummy.append(results[experiment][seed][location][year]['downtimes'])\n",
    "            results[experiment][\"minimum\"][location][year]['downtimes'] = np.min(dummy)\n",
    "            results[experiment][\"first_q\"][location][year]['downtimes'] = np.percentile(dummy, 25)\n",
    "            results[experiment][\"average\"][location][year]['downtimes'] = np.mean(dummy)\n",
    "            results[experiment][\"third_q\"][location][year]['downtimes'] = np.percentile(dummy, 75)\n",
    "            results[experiment][\"maximum\"][location][year]['downtimes'] = np.max(dummy)\n",
    "\n",
    "# get min, avg and max avg_sense_reward\n",
    "for experiment in experiment_list:\n",
    "    for location in location_list:\n",
    "        for year in year_list:\n",
    "            dummy = []\n",
    "            for seed in seed_list:\n",
    "                avgsnsrwd = results[experiment][seed][location][year]['sense_reward_log'].mean()\n",
    "                results[experiment][seed][location][year]['avg_sense_reward'] = avgsnsrwd # add new entry\n",
    "                dummy.append(avgsnsrwd)\n",
    "            results[experiment][\"minimum\"][location][year]['avg_sense_reward'] = np.min(dummy)\n",
    "            results[experiment][\"first_q\"][location][year]['avg_sense_reward'] = np.percentile(dummy, 25)\n",
    "            results[experiment][\"average\"][location][year]['avg_sense_reward'] = np.mean(dummy)\n",
    "            results[experiment][\"third_q\"][location][year]['avg_sense_reward'] = np.percentile(dummy, 75)\n",
    "            results[experiment][\"maximum\"][location][year]['avg_sense_reward'] = np.max(dummy)\n",
    "            \n",
    "# get min, avg and max avg_enp_reward\n",
    "for experiment in experiment_list:\n",
    "    for location in location_list:\n",
    "        for year in year_list:\n",
    "            dummy = []\n",
    "            for seed in seed_list:\n",
    "                avgenprwd = results[experiment][seed][location][year]['enp_reward_log'].mean()\n",
    "                results[experiment][seed][location][year]['avg_enp_reward'] = avgenprwd # add new entry\n",
    "                dummy.append(avgenprwd)\n",
    "            results[experiment][\"minimum\"][location][year]['avg_enp_reward'] = np.min(dummy)\n",
    "            results[experiment][\"first_q\"][location][year]['avg_enp_reward'] = np.percentile(dummy, 25)\n",
    "            results[experiment][\"average\"][location][year]['avg_enp_reward'] = np.mean(dummy)\n",
    "            results[experiment][\"third_q\"][location][year]['avg_enp_reward'] = np.percentile(dummy, 75)\n",
    "            results[experiment][\"maximum\"][location][year]['avg_enp_reward'] = np.max(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downtimes and Sense Rewards\n",
    "\n",
    "single_column_figure_width = 3.487\n",
    "double_column_figure_width = 7\n",
    "\n",
    "fig_width = single_column_figure_width\n",
    "fig_height = fig_width / 1.618\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2,\n",
    "                        ncols=1,\n",
    "                        figsize=[fig_width,fig_height], # in inches\n",
    "                        sharex=True)\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=.05)\n",
    "\n",
    "#######################################################################################\n",
    "# # left  = 0.125  # the left side of the subplots of the figure\n",
    "# # right = 0.9    # the right side of the subplots of the figure\n",
    "# # bottom = 0.1   # the bottom of the subplots of the figure\n",
    "# # top = 0.9      # the top of the subplots of the figure\n",
    "# # wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
    "# # hspace = 0.2   # the amount of height reserved for white space between subplots\n",
    "#######################################################################################\n",
    "\n",
    "sense_reward_ax  = axs[0]\n",
    "downtimes_ax = axs[1]\n",
    "\n",
    "location = 'tokyo'\n",
    "print(location)\n",
    "\n",
    "# avg_sense_reward\n",
    "for experiment in experiment_list:\n",
    "    min_data = [results[experiment][\"minimum\"][location][year]['avg_sense_reward'] for year in year_list]\n",
    "    qt1_data = [results[experiment][\"first_q\"][location][year]['avg_sense_reward'] for year in year_list]\n",
    "    avg_data = [results[experiment][\"average\"][location][year]['avg_sense_reward'] for year in year_list]\n",
    "    qt3_data = [results[experiment][\"third_q\"][location][year]['avg_sense_reward'] for year in year_list]\n",
    "    max_data = [results[experiment][\"maximum\"][location][year]['avg_sense_reward'] for year in year_list]\n",
    "\n",
    "    \n",
    "#     sense_reward_ax.fill_between(year_list, y1=qt1_data, y2=qt3_data, \n",
    "#                                  color=experiment_color[experiment],\n",
    "#                                  alpha=0.2)\n",
    "    if experiment == experiment_list[0]:\n",
    "        sense_reward_ax.plot(year_list, avg_data, \n",
    "                             color=experiment_color[experiment], \n",
    "                             label=experiment_label[experiment],\n",
    "                             linestyle='--',\n",
    "                            )\n",
    "    else:\n",
    "        sense_reward_ax.plot(year_list, avg_data, \n",
    "                             color=experiment_color[experiment], \n",
    "                             label=experiment_label[experiment]\n",
    "                            )\n",
    "    \n",
    "sense_reward_ax.text(0.035,0.5, 'sense-utility', \n",
    "         size='x-small', ha='center', va='center', \n",
    "        rotation='vertical',  transform=sense_reward_ax.transAxes)\n",
    "# sense_reward_ax.set_title('sense utility')\n",
    "# sense_reward_ax.set_ylabel('sense utility')    \n",
    "sense_reward_ax.legend(loc=\"lower left\",\n",
    "                       ncol=2,\n",
    "                       fontsize='x-small',\n",
    "                        bbox_to_anchor=(-0.02,0.95,1.04,1),\n",
    "                        mode=\"expand\",\n",
    "                       labelspacing=0.1,)\n",
    "sense_reward_ax.grid(which='major', axis='x', linestyle='--')\n",
    "\n",
    "# Downtimes\n",
    "for experiment in experiment_list:\n",
    "    min_data = [results[experiment][\"minimum\"][location][year]['downtimes'] for year in year_list]\n",
    "    qt1_data = [results[experiment][\"first_q\"][location][year]['downtimes'] for year in year_list]\n",
    "    avg_data = [results[experiment][\"average\"][location][year]['downtimes'] for year in year_list]\n",
    "    qt3_data = [results[experiment][\"third_q\"][location][year]['downtimes'] for year in year_list]\n",
    "    max_data = [results[experiment][\"maximum\"][location][year]['downtimes'] for year in year_list]\n",
    "    \n",
    "    width = 0.8/len(experiment_list)  # the width of the bars \n",
    "    xroot = np.array(year_list) # label locations\n",
    "    xoffset = -0.8/2 + experiment_list.index(experiment) \n",
    "    downtimes_ax.bar(xroot+xoffset*width, avg_data,width, \n",
    "#                      yerr = [qt1_data,qt3_data], \n",
    "                     color=experiment_color[experiment], \n",
    "                     label=experiment_label[experiment],\n",
    "                     error_kw=dict(ecolor='black', lw=1, capsize=0.5, capthick=width*0.5, alpha=0.2))\n",
    "\n",
    "downtimes_ax.set_xticks(year_list[::1])\n",
    "downtimes_ax.set_xticklabels(year_list[::1], rotation=0)\n",
    "\n",
    "downtimes_ax.text(0.15,0.85, 'Downtimes', \n",
    "                 size='x-small', ha=\"center\", \n",
    "                 transform=downtimes_ax.transAxes)\n",
    "# downtimes_ax.set_title('downtimes')\n",
    "# downtimes_ax.set_ylabel('downtimes')    \n",
    "# downtimes_ax.legend(loc=\"lower left\",\n",
    "#                    ncol=1,\n",
    "#                    bbox_to_anchor=(0,0.8,1,1))\n",
    "downtimes_ax.grid(which='major', axis='y', linestyle='--')\n",
    "fig.savefig('./figures/base-morl_offpolicy_const-test.png', dpi=300, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
